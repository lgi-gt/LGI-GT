


===============================================
2022-11-15 23:17:50

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 42

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 42
device: 1
save_state: False


Run time: 5747.466265928
Best Epoch: 86
Val: 0.7850
Test Score: 0.7818



===============================================
2022-11-16 01:52:56

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 42

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 42
device: 0
save_state: False


Run time: 5506.154753386043
Best Epoch: 80
Val: 0.7847
Test Score: 0.7834



===============================================
2022-11-16 01:53:23

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 42

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 42
device: 1
save_state: False


Run time: 5583.714934621938
Best Epoch: 95
Val: 0.7839
Test Score: 0.7822



===============================================
2022-11-16 03:26:36

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 314159

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 314159
device: 1
save_state: False


Run time: 5400.713687135023
Best Epoch: 92
Val: 0.7832
Test Score: 0.7829



===============================================
2022-11-16 03:24:50

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 314159

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 314159
device: 0
save_state: False


Run time: 5532.394725274062
Best Epoch: 76
Val: 0.7835
Test Score: 0.7826



===============================================
2022-11-16 04:56:45

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 271828

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 271828
device: 1
save_state: False


Run time: 5516.61859287892
Best Epoch: 90
Val: 0.7861
Test Score: 0.7807



===============================================
2022-11-16 04:57:11

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 271828

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 271828
device: 0
save_state: False


Run time: 5682.139295045054
Best Epoch: 72
Val: 0.7861
Test Score: 0.7830



===============================================
2022-11-16 06:28:50

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 2020

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 2020
device: 1
save_state: False


Run time: 5487.868747561006
Best Epoch: 87
Val: 0.7831
Test Score: 0.7792



===============================================
2022-11-16 06:32:02

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 2020

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 2020
device: 0
save_state: False


Run time: 5519.502340399893
Best Epoch: 72
Val: 0.7818
Test Score: 0.7817



===============================================
2022-11-16 08:00:26

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 2022

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 2022
device: 1
save_state: False


Run time: 5619.335831969976
Best Epoch: 86
Val: 0.7837
Test Score: 0.7801



===============================================
2022-11-16 08:04:11

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 2022

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 2022
device: 0
save_state: False


Run time: 5400.005703305011
Best Epoch: 60
Val: 0.7819
Test Score: 0.7802



===============================================
2022-11-16 09:34:20

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 2333

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 2333
device: 0
save_state: False


Run time: 5465.1223338700365
Best Epoch: 61
Val: 0.7826
Test Score: 0.7813



===============================================
2022-11-16 09:34:14

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 2333

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 2333
device: 1
save_state: False


Run time: 5599.837976825074
Best Epoch: 61
Val: 0.7828
Test Score: 0.7829



===============================================
2022-11-16 11:05:33

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 23333

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 23333
device: 0
save_state: False


Run time: 5274.629635805031
Best Epoch: 85
Val: 0.7841
Test Score: 0.7806



===============================================
2022-11-16 11:07:42

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 23333

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 23333
device: 1
save_state: False


Run time: 5435.274636526941
Best Epoch: 99
Val: 0.7834
Test Score: 0.7820



===============================================
2022-11-16 12:33:36

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 12138

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 12138
device: 0
save_state: False


Run time: 5520.802656320971
Best Epoch: 94
Val: 0.7834
Test Score: 0.7820



===============================================
2022-11-16 12:38:26

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 12138

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 12138
device: 1
save_state: False


Run time: 5492.826689239009
Best Epoch: 79
Val: 0.7837
Test Score: 0.7827



===============================================
2022-11-16 14:05:46

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 666

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 666
device: 0
save_state: False


Run time: 5676.567175837001
Best Epoch: 66
Val: 0.7835
Test Score: 0.7820



===============================================
2022-11-16 14:10:07

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 666

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 666
device: 1
save_state: False


Run time: 5763.6201081529725
Best Epoch: 97
Val: 0.7836
Test Score: 0.7799



===============================================
2022-11-16 15:40:32

main.py --device 0 --attn-dropout 0.5 --tlayer-dropout 0.1 --lr 0.001 --num-heads 8 --scheduler cosine --seeds 886

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: cosine
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.5
tlayer_dropout: 0.1
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 8
skip_connection: short
seeds: 886
device: 0
save_state: False


Run time: 5457.649643599056
Best Epoch: 65
Val: 0.7820
Test Score: 0.7817



===============================================
2022-11-16 15:46:19

main.py --device 1 --lr 0.001 --attn-dropout 0.2 --tlayer-dropout 0.2 --scheduler linear --seeds 886

None

baseline: SAT
dataset: CLUSTER
use_val_loss: False
use_cpu: False
max_freqs: 16
eigvec_norm: L2
num_rw_steps: 6
num_classes: 6
epochs: 100
scheduler: linear
warmup: 5
batch_size: 32
lr: 0.001
weight_decay: 1e-05
num_workers: 0
clustering: False
masked_attention: True
gconv_dim: 48
dim_pe: 16
tlayer_dim: 48
gconv_dropout: 0
attn_dropout: 0.2
tlayer_dropout: 0.2
classifier_head_dropout: 0.3
num_layers: 16
num_heads: 4
skip_connection: short
seeds: 886
device: 1
save_state: False


Run time: 5631.874908984988
Best Epoch: 87
Val: 0.7825
Test Score: 0.7824

