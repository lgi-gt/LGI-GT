{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.1860), tensor(0.6963))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# parser.add_argument('--epochs', type=int, default=200) \n",
    "# parser.add_argument('--warmup', type=int, default=10) \n",
    "# parser.add_argument('--weight-decay', type=float, default=1e-4) \n",
    "\n",
    "# hidden_dim=128, num_layers=4, transformer dropout_ratio=0.2, ginconv dropout ratio=0.0, \n",
    "# dropout_ratio between ginconv and transformer = 0.5, all LayerNorm, no BatchNorm1d, \n",
    "# readout=mean, no relu between ginconv and transformer \n",
    "# long skip connection to the output\n",
    "\n",
    "# --batch-size 64 --lr 0.0001 --warmup 50 --scheduler-type linear\n",
    "\n",
    "result = torch.tensor([ \n",
    "    70.57, 69.76, 71.06, 69.37, 71.16, 69.14, 70.10, 69.85, 70.02, 70.83\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.3500), tensor(0.6823))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second time of immediate above settings \n",
    "\n",
    "result = torch.tensor([ \n",
    "    70.58, 71.11, 71.10, 69.95, 69.41, 70.16, 69.95, 71.49, 69.82, 69.93\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.5490), tensor(0.7751))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# third time \n",
    "\n",
    "result = torch.tensor([ \n",
    "    69.29, 70.27, 71.04, 71.17, 70.82, 69.99, 70.06, 71.03, 69.91, 71.91\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.2890), tensor(1.0895))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forth time  \n",
    "\n",
    "result = torch.tensor([ \n",
    "    72.57, 70.24, 71.09, 70.02, 70.22, 69.82, 69.38, 71.06, 69.93, 68.56\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.5440), tensor(0.8023))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fifth time \n",
    "\n",
    "result = torch.tensor([ \n",
    "    70.59, 71.26, 69.89, 69.20, 71.35, 71.74, 70.28, 69.90, 70.13, 71.10\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.5160), tensor(0.7269))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt, clustering (softmax alongside dim=1) but no inf mask \n",
    "# A = torch.softmax(attention_score, 1) \n",
    "\n",
    "import torch \n",
    "result = torch.tensor([ \n",
    "    70.05, 71.04, 70.65, 69.85, 71.42, 69.47, 71.15, 71.50, 70.11, 69.92\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.3630), tensor(1.6151))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt, no clustering (softmax alongside dim=-1) but no inf mask \n",
    "# A = torch.softmax(attention_score, -1) # no clustering, no infinity mask \n",
    "\n",
    "import torch \n",
    "result = torch.tensor([ \n",
    "    70.40, 73.26, 69.49, 71.57, 69.43, 68.48, 70.24, 71.84, 70.98, 67.94\n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.2660), tensor(1.3697))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# above \n",
    "\n",
    "import torch \n",
    "\n",
    "result = torch.tensor([ \n",
    "    69.65, 68.73, 71.53, 70.48, 69.35, 71.76, 70.74, 67.89, 72.15, 70.38 \n",
    "]) \n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.3990), tensor(0.6784))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_score = attention_score / math.sqrt(self.hidden_dim)\n",
    "# A = torch.softmax(attention_score, 1) # clustering, no infinity mask \n",
    "\n",
    "import torch \n",
    "\n",
    "result = torch.tensor([ \n",
    "    70.09, 70.78, 69.49, 71.08, 69.97, 70.06, 70.21, 70.80, 71.72, 69.79\n",
    "])\n",
    "\n",
    "result.mean(), result.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(70.5540), tensor(1.2233))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_score = attention_score / math.sqrt(self.hidden_dim) \n",
    "# A = torch.softmax(attention_score, -1) # no clustering, no infinity mask \n",
    "\n",
    "result = torch.tensor([ \n",
    "    69.24, 71.16, 70.26, 70.26, 68.01, 72.12, 70.67, 70.59, 71.69, 71.54 \n",
    "])\n",
    "result.mean(), result.std() "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfe7cb134f73dfab38ea71f95e95d39e5dab0c14c773e85f09e4509617755691"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('genv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
